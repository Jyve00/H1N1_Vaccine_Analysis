{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler, OrdinalEncoder, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "# stops python from showing scientific notation\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/stephen/Flatiron/Phase3/project_3/Data/training_set_features.csv', index_col='respondent_id')\n",
    "target = pd.read_csv('/Users/stephen/Flatiron/Phase3/project_3/Data/training_set_labels.csv', index_col='respondent_id')\n",
    "holdout_set = pd.read_csv('/Users/stephen/Flatiron/Phase3/project_3/Data/test_set_features.csv', index_col='respondent_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need the 'h1n1_vaccine' column as our target variable so we'll turn it into a panda series with just that column. \n",
    "target = pd.Series(target['h1n1_vaccine'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.79\n",
       "1   0.21\n",
       "Name: h1n1_vaccine, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the values \n",
    "target.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop unnecessary columns in features\n",
    "drop_feats = ['opinion_seas_vacc_effective','opinion_seas_risk','opinion_seas_sick_from_vacc','hhs_geo_region',\n",
    "            'employment_industry','employment_occupation','census_msa']\n",
    "\n",
    "features = data.drop(columns=drop_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26707 entries, 0 to 26706\n",
      "Data columns (total 28 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 26615 non-null  float64\n",
      " 1   h1n1_knowledge               26591 non-null  float64\n",
      " 2   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 3   behavioral_avoidance         26499 non-null  float64\n",
      " 4   behavioral_face_mask         26688 non-null  float64\n",
      " 5   behavioral_wash_hands        26665 non-null  float64\n",
      " 6   behavioral_large_gatherings  26620 non-null  float64\n",
      " 7   behavioral_outside_home      26625 non-null  float64\n",
      " 8   behavioral_touch_face        26579 non-null  float64\n",
      " 9   doctor_recc_h1n1             24547 non-null  float64\n",
      " 10  doctor_recc_seasonal         24547 non-null  float64\n",
      " 11  chronic_med_condition        25736 non-null  float64\n",
      " 12  child_under_6_months         25887 non-null  float64\n",
      " 13  health_worker                25903 non-null  float64\n",
      " 14  health_insurance             14433 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 16  opinion_h1n1_risk            26319 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 18  age_group                    26707 non-null  object \n",
      " 19  education                    25300 non-null  object \n",
      " 20  race                         26707 non-null  object \n",
      " 21  sex                          26707 non-null  object \n",
      " 22  income_poverty               22284 non-null  object \n",
      " 23  marital_status               25299 non-null  object \n",
      " 24  rent_or_own                  24665 non-null  object \n",
      " 25  employment_status            25244 non-null  object \n",
      " 26  household_adults             26458 non-null  float64\n",
      " 27  household_children           26458 non-null  float64\n",
      "dtypes: float64(20), object(8)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Ordinal categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = features.select_dtypes('number').columns\n",
    "ord_cols = ['age_group', 'education',  'income_poverty', 'employment_status']\n",
    "cat_cols = ['race', 'sex', 'marital_status', 'rent_or_own']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65+ Years        6843\n",
       "55 - 64 Years    5563\n",
       "45 - 54 Years    5238\n",
       "18 - 34 Years    5215\n",
       "35 - 44 Years    3848\n",
       "Name: age_group, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['age_group'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    6843\n",
       "4    5563\n",
       "3    5238\n",
       "1    5215\n",
       "2    3848\n",
       "Name: age_group_ordinal, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give categories values \n",
    "\n",
    "age_group_dict = {\n",
    "np.NAN: -1, \n",
    "'18 - 34 Years': 1, \n",
    "'35 - 44 Years': 2, \n",
    "'45 - 54 Years': 3, \n",
    "'55 - 64 Years': 4, \n",
    "'65+ Years': 5, \n",
    "}\n",
    "\n",
    "features['age_group_ordinal'] = features.age_group.map(age_group_dict).astype(\"category\")\n",
    "features['age_group_ordinal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "College Graduate    10097\n",
       "Some College         7043\n",
       "12 Years             5797\n",
       "< 12 Years           2363\n",
       "NaN                  1407\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['education'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1     1407\n",
       "1      2363\n",
       "2      5797\n",
       "3      7043\n",
       "4     10097\n",
       "Name: education_ordinal, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_dict = {\n",
    "    np.NAN: -1,\n",
    "    '< 12 Years': 1, \n",
    "    '12 Years': 2, \n",
    "    'Some College': 3, \n",
    "    'College Graduate': 4\n",
    "}\n",
    "\n",
    "features['education_ordinal'] = features.education.map(education_dict).astype(\"category\")\n",
    "features['education_ordinal'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<= $75,000, Above Poverty    12777\n",
       "> $75,000                     6810\n",
       "Below Poverty                 2697\n",
       "Name: income_poverty, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['income_poverty'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employed              13560\n",
       "Not in Labor Force    10231\n",
       "Unemployed             1453\n",
       "Name: employment_status, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['employment_status'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     13560\n",
       "2     10231\n",
       "-1     1463\n",
       "1      1453\n",
       "Name: employment_status_ordinal, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employment_dict = { \n",
    "    np.NAN: -1,\n",
    "    'Unemployed': 1, \n",
    "    'Not in Labor Force': 2, \n",
    "    'Employed': 3\n",
    "}\n",
    "\n",
    "features['employment_status_ordinal'] = features.employment_status.map(employment_dict).astype(\"category\")\n",
    "features['employment_status_ordinal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26707, 31)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(columns=ord_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "respondent_id\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "26702    0\n",
       "26703    0\n",
       "26704    0\n",
       "26705    0\n",
       "26706    0\n",
       "Name: h1n1_vaccine, Length: 26707, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.SMOTE'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-e87e54f800b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mlor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m clf = Pipeline([('preprocessor', preprocessor),('smt', smt),\n\u001b[0m\u001b[1;32m     22\u001b[0m                 ('lor',lor)])\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m             if (not (hasattr(t, \"fit\") or hasattr(t, \"fit_transform\")) or not\n\u001b[1;32m    158\u001b[0m                     hasattr(t, \"transform\")):\n\u001b[0;32m--> 159\u001b[0;31m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[0m\u001b[1;32m    160\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                                 \u001b[0;34m\"or be the string 'passthrough' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.SMOTE'>) doesn't"
     ]
    }
   ],
   "source": [
    "numeric_preprocessing_steps = Pipeline(steps=[('poly',PolynomialFeatures(degree = 2)),\n",
    "                                      ('scaler', StandardScaler())])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('cat_imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "\n",
    "# create the preprocessor stage of final pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('numeric', numeric_preprocessing_steps, num_cols), \n",
    "        ('category', cat_transformer, cat_cols)],\n",
    "    remainder = \"passthrough\")\n",
    "\n",
    "#estimators = LogisticRegression(penalty=\"l2\", C=1, class_weight='balanced')\n",
    "smt = SMOTE(random_state=42)\n",
    "lor = LogisticRegression(C = 50)\n",
    "\n",
    "clf = Pipeline([('preprocessor', preprocessor),('smt', smt),\n",
    "                ('lor',lor)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into a test set and a train set \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=42, test_size=0.25, stratify=target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at pipeline\n",
    "full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training set \n",
    "full_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(full_pipeline, X_test, y_test, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f', (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = full_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(full_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17cc554a2c16bc39ba98993395725f2ec0bd4b482a8c6c7a1f8b97bbfb728cd1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
